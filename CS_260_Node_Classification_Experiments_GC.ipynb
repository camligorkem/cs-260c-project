{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS_260_Node_Classification_Experiments_GC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camligorkem/cs-260c-project/blob/main/CS_260_Node_Classification_Experiments_GC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1op-CbyLuN4"
      },
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize(h, color):\n",
        "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "from torch_geometric.utils import degree\n",
        "import torch_geometric\n",
        "import torch_geometric.utils as tg_utils\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5zzyCFITsi1f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data"
      ],
      "metadata": {
        "id": "4XbHNyORvbNu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imGrKO5YH11-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d156dce6-b010-4ce9-9a00-026cbf96a8b2"
      },
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: Cora():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "\n",
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
            "===========================================================================================================\n",
            "Number of nodes: 2708\n",
            "Number of edges: 10556\n",
            "Average node degree: 3.90\n",
            "Number of training nodes: 140\n",
            "Training node label rate: 0.05\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_masked_noise(data,  noise_level=0.15):\n",
        "  x = data.x\n",
        "  noise_added_node_num = int(noise_level * x.shape[0])\n",
        "  chose_random_rows = np.random.choice(x.shape[0], noise_added_node_num, replace=False)\n",
        "  #print(chose_random_rows)\n",
        "  mask_rows = torch.zeros(x.shape)\n",
        "  mask_rows[chose_random_rows,:] = torch.ones(1, x.shape[1])\n",
        "  noise = (0.1**0.5)*torch.randn(x.shape)\n",
        "  masked_noise = noise* mask_rows.int().float()\n",
        "\n",
        "  #print(mask_rows)\n",
        "  #print(noise)\n",
        "  #print(masked_noise)\n",
        "  return x + masked_noise"
      ],
      "metadata": {
        "id": "W45Hs6203FyL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove x% edges\n",
        "def remove_from_all_edges(data, noise_level = 0.15, bidirectional=False):\n",
        "  edge_index = data.edge_index\n",
        "\n",
        "  if bidirectional:\n",
        "    noise_level /= 2\n",
        "  \n",
        "  edge_ratio_to_keep = 1 - noise_level\n",
        "  num_edges_keep= int(edge_ratio_to_keep * edge_index.shape[1])\n",
        "  chose_random_edge_indices = np.random.choice(edge_index.shape[1], num_edges_keep, replace=False)\n",
        "\n",
        "  #print(edge_index[0][chose_random_edge_indices].shape)\n",
        "  #print(num_edges_keep)\n",
        "  #print(edge_index.shape[1])\n",
        "\n",
        "  edge_index_removed = torch.zeros((2,num_edges_keep), dtype=torch.int64)\n",
        "  edge_index_removed[0] = edge_index[0][chose_random_edge_indices]\n",
        "  edge_index_removed[1] = edge_index[1][chose_random_edge_indices]\n",
        "\n",
        "  if bidirectional:\n",
        "    # find the node names deleted in below indices and delete also for the opposite side.\n",
        "    final_edges_bidirec_0 = []\n",
        "    final_edges_bidirec_1 = []\n",
        "\n",
        "    # create a set with all edges\n",
        "    edge_maps = set()\n",
        "    for e_0, e_1 in zip(edge_index_removed[0], edge_index_removed[1]):\n",
        "      edge_maps.add((e_0.item(),e_1.item()))\n",
        "\n",
        "    for e_0, e_1 in zip(edge_index_removed[0], edge_index_removed[1]):\n",
        "      e_0_val = e_0.item()\n",
        "      e_1_val = e_1.item()\n",
        "      # check an edge has its other direction, if yes add to the final list, if not skip\n",
        "      if (e_0_val, e_1_val) in edge_maps and (e_1_val, e_0_val) in edge_maps:\n",
        "        final_edges_bidirec_0.append(e_0_val) \n",
        "        final_edges_bidirec_1.append(e_1_val)\n",
        "\n",
        "    final_edges_bidirec_0 = torch.tensor(final_edges_bidirec_0)\n",
        "    final_edges_bidirec_1 = torch.tensor(final_edges_bidirec_1)\n",
        "    edge_index_removed = torch.zeros((2,len(final_edges_bidirec_1)), dtype=torch.int64)\n",
        "    edge_index_removed[0] = final_edges_bidirec_0\n",
        "    edge_index_removed[1] = final_edges_bidirec_1\n",
        "\n",
        "  return edge_index_removed\n",
        "\n"
      ],
      "metadata": {
        "id": "LpEb0WU4CDR8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove x% edges from random k, top_k, bottom_k nodes\n",
        "\n",
        "def choose_nodes(data, num_nodes, k_nodes, choose_type):\n",
        "  if choose_type=='random':\n",
        "    nodes_chosen = torch.from_numpy(np.random.choice(num_nodes, k_nodes, replace=False))\n",
        "  elif choose_type=='top_k':\n",
        "    # find indegree edges\n",
        "    dg = torch_geometric.utils.degree(data.edge_index[0])\n",
        "    top_k_nodes_degrees, top_k_nodes_indices = torch.topk(dg, k_nodes)\n",
        "    #print(top_k_nodes_degrees, top_k_nodes_indices)\n",
        "    nodes_chosen = top_k_nodes_indices\n",
        "  elif choose_type=='bottom_k':\n",
        "    # find indegree edges\n",
        "    dg = torch_geometric.utils.degree(data.edge_index[0])\n",
        "    bottom_k_nodes_degrees, bottom_k_nodes_indices = torch.topk(dg, k_nodes, largest=False)\n",
        "    #print(bottom_k_nodes_degrees, bottom_k_nodes_indices)\n",
        "    nodes_chosen = bottom_k_nodes_indices\n",
        "  else:\n",
        "    raise 'choose_type should be from random, top_k, bottom_k'\n",
        "  return nodes_chosen\n",
        "\n",
        "# to do loop for each node separately\n",
        "def remove_edges_from_chosen_nodes(data, nodes_chosen, edges_to_remove_per_node_ratio):\n",
        "  edges_0_list, edges_1_list = [],[]\n",
        "  for nc in nodes_chosen:\n",
        "    edge_0, edge_1 = remove_edge_per_node(data=data, node=nc, \n",
        "                                          edges_to_remove_per_node_ratio=edges_to_remove_per_node_ratio)\n",
        "    edges_0_list.append(edge_0)\n",
        "    edges_1_list.append(edge_1)\n",
        "\n",
        "  edges_0 = torch.cat(edges_0_list, 0)\n",
        "  edges_1 = torch.cat(edges_1_list, 0)\n",
        "\n",
        "  return edges_0, edges_1\n",
        "\n",
        "def remove_edge_per_node(data, node, edges_to_remove_per_node_ratio=0.1):\n",
        "  mask_node_indices = torch.isin(data.edge_index[0], node)\n",
        "\n",
        "  select_node_edges_0 = data.edge_index[0][mask_node_indices]\n",
        "  select_node_edges_1 = data.edge_index[1][mask_node_indices]\n",
        "  #print(select_node_edges_0)\n",
        "  #print(select_node_edges_1)\n",
        "\n",
        "  # choose how much of the edges we will remove for this node\n",
        "  # we decide on number of edges to remove for each node based on the number of edges each node has\n",
        "  # and by taking the ratio given by edges_to_remove_per_node_ratio\n",
        "  # note: we use ceil to remove at least one node (unless ratio is 0)\n",
        "  num_edges_remove = int(math.ceil(edges_to_remove_per_node_ratio* select_node_edges_0.shape[0]))\n",
        "  # print(num_edges_remove)\n",
        "  num_edges_keep = select_node_edges_0.shape[0] - num_edges_remove\n",
        "\n",
        "  # choose random edges to keep, the rest is removed\n",
        "  chose_random_edge_indices = np.random.choice(select_node_edges_0.shape[0], num_edges_keep, replace=False)\n",
        "  # print(num_edges_keep)\n",
        "  \n",
        "  edge_index_removed = torch.zeros((2,num_edges_keep), dtype=torch.int64)\n",
        "  edge_node_index_removed_0 = select_node_edges_0[chose_random_edge_indices]\n",
        "  edge_node_index_removed_1 = select_node_edges_1[chose_random_edge_indices]\n",
        "\n",
        "  return edge_node_index_removed_0, edge_node_index_removed_1\n",
        "\n",
        "def remove_edges_from_nodes(data, noise_level = 0.15, k_nodes=10,\n",
        "                            choose_type='random', bidirectional=False):\n",
        "  if bidirectional:\n",
        "    noise_level /= 2\n",
        "\n",
        "  edge_p_node_ratio_to_keep = 1 - noise_level\n",
        "\n",
        "  # choose topk, bottomk, or random\n",
        "  nodes_chosen = choose_nodes(data=data, num_nodes=data.num_nodes, k_nodes=k_nodes, choose_type=choose_type)\n",
        "\n",
        "  # keep edges from remaining nodes\n",
        "  mask_node_indices = torch.isin(data.edge_index[0],nodes_chosen)\n",
        "  index_keep = torch.ones(data.edge_index[0].shape[0], dtype=bool)\n",
        "  index_keep[mask_node_indices] = False\n",
        "  edges_to_keep_0 = data.edge_index[0][index_keep]\n",
        "  edges_to_keep_1 = data.edge_index[1][index_keep]\n",
        "  #print(edges_to_keep_0) \n",
        "  #print(edges_to_keep_1)\n",
        "\n",
        "  # remove one-directional or bi-directional\n",
        "  edges_0_kept_chosen_nodes, edges_1_kept_chosen_nodes = remove_edges_from_chosen_nodes(data=data, \n",
        "                                                                                        nodes_chosen=nodes_chosen,\n",
        "                                                                                        edges_to_remove_per_node_ratio=noise_level)\n",
        "  # concat edges to keep and edges_kept_chosen_nodes\n",
        "  final_edges_0 = torch.cat([edges_to_keep_0, edges_0_kept_chosen_nodes], 0)\n",
        "  final_edges_1 = torch.cat([edges_to_keep_1, edges_1_kept_chosen_nodes], 0)\n",
        "\n",
        "  # do bidirectional here! IF bidirectional set to true remove both directions of the edges.\n",
        "  if bidirectional:\n",
        "    # find the node names deleted in below indices and delete also for the opposite side.\n",
        "    final_edges_bidirec_0 = []\n",
        "    final_edges_bidirec_1 = []\n",
        "\n",
        "    # create a set with all edges\n",
        "    edge_maps = set()\n",
        "    for e_0, e_1 in zip(final_edges_0, final_edges_1):\n",
        "      edge_maps.add((e_0.item(),e_1.item()))\n",
        "\n",
        "    for e_0, e_1 in zip(final_edges_0, final_edges_1):\n",
        "      e_0_val = e_0.item()\n",
        "      e_1_val = e_1.item()\n",
        "      # check an edge has its other direction, if yes add to the final list, if not skip\n",
        "      if (e_0_val, e_1_val) in edge_maps and (e_1_val, e_0_val) in edge_maps:\n",
        "        final_edges_bidirec_0.append(e_0_val) \n",
        "        final_edges_bidirec_1.append(e_1_val)\n",
        "\n",
        "    final_edges_bidirec_0 = torch.tensor(final_edges_bidirec_0)\n",
        "    final_edges_bidirec_1 = torch.tensor(final_edges_bidirec_1)\n",
        "    final_edges_0 = final_edges_bidirec_0\n",
        "    final_edges_1 = final_edges_bidirec_1\n",
        "  edge_index_removed = torch.zeros((2, final_edges_0.shape[0]), dtype=torch.int64)\n",
        "  edge_index_removed[0] = final_edges_0\n",
        "  edge_index_removed[1] = final_edges_1\n",
        "\n",
        "    \n",
        "  # use TORCH_GEOMETRIC.UTILS.SORT_EDGE_INDEX\n",
        "  edge_index_removed_sorted = tg_utils.sort_edge_index(edge_index_removed)\n",
        "  return edge_index_removed_sorted\n"
      ],
      "metadata": {
        "id": "0WSp747oA8MS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_random_edges(data, noise_level = 0.15, bidirectional=False):\n",
        "  edge_index = data.edge_index\n",
        "  num_nodes = data.num_nodes\n",
        "\n",
        "  if bidirectional:\n",
        "    noise_level /= 2\n",
        "\n",
        "  new_edges = edge_index.T\n",
        "  edge_num = new_edges.shape[0]\n",
        "  num_of_new_edges = int(edge_num * noise_level)\n",
        "\n",
        "  for i in range(num_of_new_edges):\n",
        "    while True:\n",
        "      new_edge = ((torch.rand(1,2) * 1000000).to(int) % num_nodes)\n",
        "      new_edge_flip = torch.flip(new_edge, [1])\n",
        "      new_edge_exist = torch.any(torch.all(torch.eq(new_edges,new_edge),1))\n",
        "      new_edge_flip_exist = torch.any(torch.all(torch.eq(new_edges,new_edge_flip),1))\n",
        "      if not new_edge_exist and not new_edge_flip_exist:\n",
        "        new_edges = torch.cat((new_edges,new_edge), 0)\n",
        "        if bidirectional:\n",
        "          new_edges = torch.cat((new_edges,new_edge_flip), 0)\n",
        "        break\n",
        "      elif not new_edge_exist:\n",
        "        new_edges = torch.cat((new_edges,new_edge), 0)\n",
        "        break\n",
        "      elif not new_edge_flip_exist:\n",
        "        new_edges = torch.cat((new_edges,new_edge_flip), 0)\n",
        "        break\n",
        "\n",
        "  edge_index_sorted = tg_utils.sort_edge_index(new_edges.T)\n",
        "  return edge_index_sorted"
      ],
      "metadata": {
        "id": "Ng5JaRtrBctF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for added_ratio in [0.15]:\n",
        "  new_edges = add_random_edges(data,  noise_level=added_ratio, bidirectional=True)\n",
        "  data[f'edge_index_added_n_{added_ratio}'] = new_edges\n"
      ],
      "metadata": {
        "id": "xbJwlz_CRnm7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Helper function of add_edges_to_nodes\n",
        "\n",
        "def add_edges_to_a_node(data, new_edges, node, num_to_add=0, bidirectional=False):\n",
        "  for i in range(num_to_add):\n",
        "\n",
        "    # Running till we find the right edge to add\n",
        "    while True:\n",
        "      #create a random node. 1000000 is a arbitrary number which can be replaced to any number bigger than data.num_nodes\n",
        "      new_index = ((torch.rand(1) * 1000000).to(int) % data.num_nodes).item()\n",
        "      new_edge = torch.tensor([[node, new_index]])\n",
        "      new_edge_flip = torch.flip(new_edge, [1])\n",
        "      #check whether the new edge and flip one exists or not \n",
        "      new_edge_exist = torch.any(torch.all(torch.eq(new_edges,new_edge),1))\n",
        "      new_edge_flip_exist = torch.any(torch.all(torch.eq(new_edges,new_edge_flip),1))\n",
        "      if not new_edge_exist and not new_edge_flip_exist:\n",
        "        new_edges = torch.cat((new_edges,new_edge), 0)\n",
        "        if bidirectional:\n",
        "          new_edges = torch.cat((new_edges,new_edge_flip), 0)\n",
        "        break\n",
        "      elif not new_edge_exist:\n",
        "        new_edges = torch.cat((new_edges,new_edge), 0)\n",
        "        break\n",
        "      elif not new_edge_flip_exist:\n",
        "        new_edges = torch.cat((new_edges,new_edge_flip), 0)\n",
        "        break\n",
        "  return new_edges\n",
        "\n",
        "## Adding x% edges to random k, top k, or bottom k nodes\n",
        "\n",
        "def add_edges_to_nodes(data, noise_level=0.15, k_nodes=10, chosse_type='random', bidirectional=False):\n",
        "  if bidirectional:\n",
        "    noise_level /= 2\n",
        "\n",
        "  #choose nodes by three different types\n",
        "  nodes_chosen = choose_nodes(data=data, num_nodes=data.num_nodes, k_nodes=k_nodes, choose_type=chosse_type)\n",
        "  \n",
        "  new_edges = data.edge_index.T\n",
        "\n",
        "  #add new edges to every chosen node\n",
        "  for node in nodes_chosen:\n",
        "    edge_num_of_node = torch.isin(data.edge_index, node).to(int).sum()\n",
        "    edge_num_to_add = int(edge_num_of_node * noise_level)\n",
        "    \n",
        "    new_edges = add_edges_to_a_node(data, new_edges, node.item(), edge_num_to_add, bidirectional)\n",
        "  \n",
        "  edge_index_sorted = tg_utils.sort_edge_index(new_edges.T)\n",
        "  return edge_index_sorted"
      ],
      "metadata": {
        "id": "lIv7-FHio7Mi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "rjNLcKtsFINa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install class-resolver\n",
        "\n",
        "from torch_geometric.nn import MLP, GCN, GraphSAGE, GAT\n",
        "from class_resolver import ClassResolver"
      ],
      "metadata": {
        "id": "6dFYd36OHrGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3bf5bf-42e0-4f86-be61-52be01923455"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting class-resolver\n",
            "  Downloading class_resolver-0.3.4-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: class-resolver\n",
            "Successfully installed class-resolver-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model_name, model_params):\n",
        "  # add more model from here if needed: https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#models\n",
        "  # you can also check model parameters from above\n",
        "  model = None\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  if model_name=='MLP':\n",
        "    model = MLP(**model_params).to(device)\n",
        "  elif model_name=='GNN':\n",
        "    model = GCN(**model_params).to(device)\n",
        "  elif model_name=='GAT':\n",
        "    model = GAT(**model_params).to(device)\n",
        "  elif model_name=='Graphsage':\n",
        "    model = GraphSAGE(**model_params).to(device)\n",
        "  else:\n",
        "    raise 'Model names should be within MLP, GNN, GAT, Graphsage'\n",
        "  return model"
      ],
      "metadata": {
        "id": "kdZQRQArFJs8"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating MLP example, add all parameters you want to use to create/tune model in the below dictionary\n",
        "model_params= {'in_channels':1433, 'hidden_channels':16, 'out_channels':7, 'num_layers':3}\n",
        "mlp_model = get_model(model_name='MLP', model_params=model_params)\n",
        "print(mlp_model)\n",
        "\n",
        "model_params= {'in_channels':1433, 'hidden_channels':16, 'out_channels':7, 'num_layers':3, 'dropout':0.1}\n",
        "gnn_model = get_model(model_name='GNN', model_params=model_params)\n",
        "print(gnn_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRxZGuGzF-Uo",
        "outputId": "cb89f411-a499-4cf3-fd43-dd2dd5e51422"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(1433, 16, 16, 7)\n",
            "GCN(1433, 7, num_layers=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_noise_function(noise_info):\n",
        "  '''\n",
        "  This function directly returns the function we created for different noise logics\n",
        "  Change the name of the function below if noise logic function name is changed.\n",
        "  '''\n",
        "  noise_fn = None \n",
        "  if noise_info['noise_type']=='feature_noise':\n",
        "    noise_fn = get_masked_noise\n",
        "  elif noise_info['noise_type']=='edge_removal':\n",
        "    if noise_info['strategy']=='all_edges' :\n",
        "      noise_fn = remove_from_all_edges\n",
        "    elif noise_info['strategy']=='nodes' :\n",
        "      noise_fn = remove_edges_from_nodes\n",
        "  elif noise_info['noise_type']=='edge_addition':\n",
        "    if noise_info['strategy']=='all_edges' :\n",
        "      noise_fn = add_random_edges\n",
        "    elif noise_info['strategy']=='nodes' :\n",
        "      noise_fn = add_edges_to_nodes\n",
        "  else:\n",
        "    raise 'Noise type should be chosen from feature_noise, edge_removal, edge_addition' \n",
        "  return noise_fn\n",
        "  \n",
        "\n",
        "def create_noised_data_for_experiment(data, noise_info):\n",
        "  '''\n",
        "  Create noised data outside of experiment, so that you can use same data in different experiments\n",
        "  '''\n",
        "  noise_data_names = []\n",
        "  noise_fn = get_noise_function(noise_info)\n",
        "  \n",
        "  if noise_info.get('strategy')=='nodes':\n",
        "    add_prefix = f\"{noise_info.get('strategy', '')}_choose_type-{noise_info['params'].get('choose_type', '')}_bidirec-{noise_info['params'].get('bidirectional', '')}\"\n",
        "  elif noise_info.get('strategy')=='all_edges':\n",
        "    add_prefix = f\"{noise_info.get('strategy', '')}_\"\n",
        "  else: \n",
        "    add_prefix=''\n",
        "\n",
        "  if noise_info.get('strategy')=='nodes':\n",
        "    for k_nodes in noise_info['k_nodes_list']:\n",
        "      for noise_level in noise_info['noise_levels']:\n",
        "        noise_data_name = f'{noise_info[\"noise_type\"]}_{add_prefix}_knodes-{k_nodes}_noiselvl-{noise_level}'\n",
        "        noise_info['params']['noise_level'] = noise_level\n",
        "        noise_info['params']['k_nodes'] = k_nodes\n",
        "        noised_data = noise_fn(**noise_info['params'])\n",
        "        data[noise_data_name] = noised_data\n",
        "        noise_data_names.append(noise_data_name)\n",
        "\n",
        "  else: # all_edges and gaussian noisee case\n",
        "    for noise_level in noise_info['noise_levels']:\n",
        "      noise_data_name = f'{noise_info[\"noise_type\"]}_{add_prefix}_noiselvl-{noise_level}'\n",
        "      noise_info['params']['noise_level'] = noise_level\n",
        "      noised_data = noise_fn(**noise_info['params'])\n",
        "      data[noise_data_name] = noised_data\n",
        "      noise_data_names.append(noise_data_name)\n",
        "  return noise_data_names\n",
        " \n",
        "# reuse train and test\n",
        "def train(model, optimizer, x_type='x', edge_type='edge_index'):\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  model.train()\n",
        "  optimizer.zero_grad()  # Clear gradients.\n",
        "  out = model(data[x_type], data[edge_type])  # Perform a single forward pass.\n",
        "  loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "  loss.backward()  # Derive gradients.\n",
        "  optimizer.step()  # Update parameters based on gradients.\n",
        "  return loss\n",
        "\n",
        "def test(model, x_type='x', edge_type='edge_index'):\n",
        "  model.eval()\n",
        "  out = model(data[x_type], data[edge_type])\n",
        "  pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "  test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
        "  test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
        "  return test_acc\n",
        "\n",
        "def validation(model, x_type='x', edge_type='edge_index'):\n",
        "  model.eval()\n",
        "  out = model(data[x_type], data[edge_type])\n",
        "  pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "  val_correct = pred[data.val_mask] == data.y[data.val_mask]  # Check against ground-truth labels.\n",
        "  val_acc = int(val_correct.sum()) / int(data.val_mask.sum())  # Derive ratio of correct predictions.\n",
        "  return val_acc\n",
        "\n",
        "def experiment(dataset_name, model_names, model_params, data, x_types, edge_types, noise_info, opt_params,  num_epochs=50, repeat_num=1, print_updates=False,print_updates_detail=False):\n",
        "  '''\n",
        "  Assumes the noisy data is already created and inside the data object (so that we can use same data sample for different models to compare)\n",
        "  '''\n",
        "  exp_count = len(x_types)*len(edge_types)*len(model_names)\n",
        "  count=0\n",
        "  res = []\n",
        "  for model_name in model_names:\n",
        "    for x_type in x_types:\n",
        "      for ed_type in edge_types:\n",
        "        count+=1\n",
        "        test_accs = []\n",
        "        for exp_num in range(1, repeat_num+1): # we will repeat experiment repeat many times, to increase results reliability\n",
        "           \n",
        "          model =  get_model(model_name=model_name, model_params=model_params[model_name])\n",
        "          optimizer = torch.optim.Adam(model.parameters(), lr=opt_params[model_name]['lr'], weight_decay=opt_params[model_name]['weight_decay']) \n",
        "          for epoch in range(num_epochs):\n",
        "              loss = train(model, optimizer, x_type=x_type, edge_type=ed_type)\n",
        "              # print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "          # we test our results in original data, no noise added ones \n",
        "          # if you want to test on noised data change them to x_type=x_type and edge_type=ed_type below\n",
        "          test_acc = test(model, x_type='x',edge_type='edge_index') \n",
        "          test_accs.append(test_acc)\n",
        "          if print_updates_detail:\n",
        "            print(f'Exp_num:{exp_num} Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "        mean_test_acc = round(np.mean(test_accs), 3)\n",
        "        # TODO we can add other metrics such as runtime to log in here later\n",
        "        exp_res = {'dataset_name': dataset_name,\n",
        "                  'model_name':model_name, 'x_type':x_type, \n",
        "                'edge_type':ed_type, 'mean_test_accuracy':str(mean_test_acc), 'test_accuracies': ','.join([str(acc) for acc in test_accs]),\n",
        "                  'num_epochs':num_epochs, 'model_params': model_params[model_name],\n",
        "                  'noise_info':noise_info, 'repeat_num':repeat_num} # TODO add more info on experiment noise_info\n",
        "        res.append(exp_res)\n",
        "        if print_updates:\n",
        "            print(f'Run {model_name}: {count}/{exp_count}: {x_type} - {ed_type} Avg. Test Accuracy: {mean_test_acc}')\n",
        "        \n",
        "        \n",
        "\n",
        "  res_df = pd.DataFrame(res, columns=exp_res.keys())\n",
        "  return res_df"
      ],
      "metadata": {
        "id": "h6gCiCVlHizi"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name='Cora'"
      ],
      "metadata": {
        "id": "S4y_HscH_G-a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nodes_percent_to_num_nodes(percents, num_nodes):\n",
        "  return [round(pct*num_nodes) for pct in percents]"
      ],
      "metadata": {
        "id": "rzVdn8iOiaSi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Model Params\n",
        "\n",
        "model_params = {\n",
        "    'GNN':{'in_channels':1433, 'hidden_channels':30, 'out_channels':7, 'num_layers':2, 'dropout':0.2, 'aggr' :'add'},\n",
        "    'GAT':{'in_channels':1433, 'hidden_channels':15, 'out_channels':7, 'num_layers':2, 'dropout':0.2},\n",
        "    'Graphsage':{'in_channels':1433, 'hidden_channels':42, 'out_channels':7, 'num_layers':2, 'dropout':0.2}\n",
        "}\n",
        "opt_params = {\n",
        "    'GNN':{'lr':0.05, 'weight_decay':1e-6}, \n",
        "    'GAT':{'lr':0.05, 'weight_decay':5e-4}, \n",
        "    'Graphsage':{'lr':0.05, 'weight_decay':5e-4}, \n",
        "}\n"
      ],
      "metadata": {
        "id": "ljoArtG94F0h"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 1 - Remove Edges: Random - nodes"
      ],
      "metadata": {
        "id": "GaKKizgSWfV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noise data creation example: remove edges -- strategy 2: remove from selected nodes\n",
        "\n",
        "# **** DONT forget to change this *****\n",
        "EXPERIMENT_FILENAME = 'Experiment_1_remove_random_nodes.csv'\n",
        "# **** DONT forget to change this *****\n",
        "\n",
        "nodes_percent = [0.05, 0.1, 0.2]  # [0.05, 0.1, 0.2, 0.25, 0.4, 0.5]\n",
        "k_nodes_list = nodes_percent_to_num_nodes(percents=nodes_percent, num_nodes=data.num_nodes)\n",
        "\n",
        "data = data.to('cpu')\n",
        "remove_edge_from_nodes_params = {'data':data, 'bidirectional':True, 'choose_type':'random'}\n",
        "\n",
        "noise_info = {'noise_type':'edge_removal', 'strategy':'nodes', 'params':remove_edge_from_nodes_params, \n",
        "              'noise_levels':[0, 0.01, 0.05, 0.1, 0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99, 1 ], \n",
        "              'k_nodes_list':k_nodes_list,\n",
        "              'noise_param_name':'noise_level'}\n",
        "\n",
        "exp_rm_random_nodes_var_names = create_noised_data_for_experiment(data=data, noise_info=noise_info)\n",
        "print(data)\n",
        "\n",
        "# Experiment on edge removal - strategy- nodes\n",
        "# Put names of the models we want to use for this experiment type\n",
        "data = data.to('cuda:0')\n",
        "model_names = ['GNN', 'GAT', 'GraphSage']\n",
        "exp_rm_random_nodes_df = experiment(dataset_name=dataset_name, model_names=model_names,\n",
        "                                    model_params=model_params, opt_params=opt_params,\n",
        "                                    data=data, x_types=['x'], edge_types=exp_rm_random_nodes_var_names,\n",
        "                                    noise_info=noise_info, num_epochs=25, repeat_num=3, print_updates=True)\n",
        "\n",
        "# Do for node strategies only\n",
        "exp_rm_random_nodes_df[['choose_type', 'bidirectional','k_nodes','noise_level']] = exp_rm_random_nodes_df.apply(lambda x: [s.split('-')[-1] for s in x['edge_type'].split('_') if '-' in s], axis=1, result_type='expand')\n",
        "data = data.to('cpu')\n",
        "exp_rm_random_nodes_df.to_csv(EXPERIMENT_FILENAME)\n",
        "exp_rm_random_nodes_df"
      ],
      "metadata": {
        "id": "LUCgpOik2mLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 2 - Remove Edges: topk - nodes"
      ],
      "metadata": {
        "id": "tF8XyeGzt4oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noise data creation example: remove edges -- strategy 2: remove from selected nodes\n",
        "\n",
        "# **** DONT forget to change this *****\n",
        "EXPERIMENT_FILENAME = 'Experiment_2_remove_topk_nodes.csv'\n",
        "# **** DONT forget to change this *****\n",
        "\n",
        "nodes_percent = [0.05, 0.1, 0.2]  # [0.05, 0.1, 0.2, 0.25, 0.4, 0.5]\n",
        "k_nodes_list = nodes_percent_to_num_nodes(percents=nodes_percent, num_nodes=data.num_nodes)\n",
        "\n",
        "data = data.to('cpu')\n",
        "remove_edge_from_nodes_params = {'data':data, 'bidirectional':True, 'choose_type':'top_k'}\n",
        "\n",
        "noise_info = {'noise_type':'edge_removal', 'strategy':'nodes', 'params':remove_edge_from_nodes_params, \n",
        "              'noise_levels':[0, 0.01, 0.05, 0.1, 0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99, 1 ], \n",
        "              'k_nodes_list':k_nodes_list,\n",
        "              'noise_param_name':'noise_level'}\n",
        "\n",
        "exp_rm_random_nodes_var_names = create_noised_data_for_experiment(data=data, noise_info=noise_info)\n",
        "print(data)\n",
        "\n",
        "# Experiment on edge removal - strategy- nodes\n",
        "# Put names of the models we want to use for this experiment type\n",
        "data = data.to('cuda:0')\n",
        "model_names = ['GNN', 'GAT', 'GraphSage']\n",
        "exp_rm_random_nodes_df = experiment(dataset_name=dataset_name, model_names=model_names,\n",
        "                                    model_params=model_params, opt_params=opt_params,\n",
        "                                    data=data, x_types=['x'], edge_types=exp_rm_random_nodes_var_names,\n",
        "                                    noise_info=noise_info, num_epochs=25, repeat_num=3, print_updates=True)\n",
        "\n",
        "# Do for node strategies only\n",
        "exp_rm_random_nodes_df[['choose_type', 'bidirectional','k_nodes','noise_level']] = exp_rm_random_nodes_df.apply(lambda x: [s.split('-')[-1] for s in x['edge_type'].split('_') if '-' in s], axis=1, result_type='expand')\n",
        "data = data.to('cpu')\n",
        "exp_rm_random_nodes_df.to_csv(EXPERIMENT_FILENAME)\n",
        "exp_rm_random_nodes_df"
      ],
      "metadata": {
        "id": "MElovzwlt4oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 3 - Remove Edges: Bottom k - nodes"
      ],
      "metadata": {
        "id": "HiWxATQ3uMIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noise data creation example: remove edges -- strategy 2: remove from selected nodes\n",
        "\n",
        "# **** DONT forget to change this *****\n",
        "EXPERIMENT_FILENAME = 'Experiment_3_remove_bottomk_nodes.csv'\n",
        "# **** DONT forget to change this *****\n",
        "\n",
        "nodes_percent = [0.05, 0.1, 0.2]  # [0.05, 0.1, 0.2, 0.25, 0.4, 0.5]\n",
        "k_nodes_list = nodes_percent_to_num_nodes(percents=nodes_percent, num_nodes=data.num_nodes)\n",
        "\n",
        "data = data.to('cpu')\n",
        "remove_edge_from_nodes_params = {'data':data, 'bidirectional':True, 'choose_type':'bottom_k'}\n",
        "\n",
        "noise_info = {'noise_type':'edge_removal', 'strategy':'nodes', 'params':remove_edge_from_nodes_params, \n",
        "              'noise_levels':[0, 0.01, 0.05, 0.1, 0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99, 1 ], \n",
        "              'k_nodes_list':k_nodes_list,\n",
        "              'noise_param_name':'noise_level'}\n",
        "\n",
        "exp_rm_random_nodes_var_names = create_noised_data_for_experiment(data=data, noise_info=noise_info)\n",
        "print(data)\n",
        "\n",
        "# Experiment on edge removal - strategy- nodes\n",
        "# Put names of the models we want to use for this experiment type\n",
        "data = data.to('cuda:0')\n",
        "model_names = ['GNN', 'GAT', 'GraphSage']\n",
        "exp_rm_random_nodes_df = experiment(dataset_name=dataset_name, model_names=model_names,\n",
        "                                    model_params=model_params, opt_params=opt_params,\n",
        "                                    data=data, x_types=['x'], edge_types=exp_rm_random_nodes_var_names,\n",
        "                                    noise_info=noise_info, num_epochs=25, repeat_num=3, print_updates=True)\n",
        "\n",
        "# Do for node strategies only\n",
        "exp_rm_random_nodes_df[['choose_type', 'bidirectional','k_nodes','noise_level']] = exp_rm_random_nodes_df.apply(lambda x: [s.split('-')[-1] for s in x['edge_type'].split('_') if '-' in s], axis=1, result_type='expand')\n",
        "data = data.to('cpu')\n",
        "exp_rm_random_nodes_df.to_csv(EXPERIMENT_FILENAME)\n",
        "exp_rm_random_nodes_df"
      ],
      "metadata": {
        "id": "Xb-VGJNZuMIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Xa4ucjwqvLJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Experiments for other experiments\n",
        "\n",
        "Old versions may need to be modified based on above."
      ],
      "metadata": {
        "id": "tzFq6i4vhN0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noise data creation example: add edges\n",
        "edge_addition_params = {'data':data}\n",
        "noise_info = {'noise_type':'edge_addition', 'params':edge_addition_params, 'noise_levels':[0.3, 0.6, 0.9 ], 'strategy': 'all_edges'}\n",
        "\n",
        "noise_var_names = create_noised_data_for_experiment(data=data, noise_info=noise_info)\n",
        "print(data)\n",
        "\n",
        "# Experiment on edge addition noise\n",
        "model_names = ['GNN', 'GAT', 'Graphsage']\n",
        "model_params = {  # TODO random params change later\n",
        "    'GNN':{'in_channels':1433, 'hidden_channels':16, 'out_channels':7, 'num_layers':3, 'dropout':0.1},\n",
        "    'GAT':{'in_channels':1433, 'hidden_channels':12, 'out_channels':7, 'num_layers':3, 'dropout':0.2},\n",
        "    'Graphsage':{'in_channels':1433, 'hidden_channels':14, 'out_channels':7, 'num_layers':3, 'dropout':0.1}\n",
        "}\n",
        "exp_df = experiment(dataset_name=dataset_name, model_names=model_names, model_params=model_params, data=data, x_types=['x'], \n",
        "           edge_types=noise_var_names, noise_info=noise_info, num_epochs=25, repeat_num=3, print_updates=True)\n",
        "\n",
        "exp_df"
      ],
      "metadata": {
        "id": "C7pMJRye8XEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noise data creation example: add noise feature\n",
        "feature_noise_params = {'x':data.x}\n",
        "noise_info = {'noise_type':'feature_noise', 'params':feature_noise_params, 'noise_levels':[0, 0.3, 0.6 ], 'noise_param_name':'noise_level'}\n",
        "\n",
        "noise_var_names_feat_exp =  create_noised_data_for_experiment(data=data, noise_info=noise_info)\n",
        "print(data)\n",
        "\n",
        "# Experiment on feature noise \n",
        "model_names = ['GNN', 'GAT']\n",
        "model_params = {  # TODO random params change later\n",
        "    'GNN':{'in_channels':1433, 'hidden_channels':16, 'out_channels':7, 'num_layers':3, 'dropout':0.1},\n",
        "    'GAT':{'in_channels':1433, 'hidden_channels':12, 'out_channels':7, 'num_layers':3, 'dropout':0.2},\n",
        "    'Graphsage':{'in_channels':1433, 'hidden_channels':14, 'out_channels':7, 'num_layers':3, 'dropout':0.1}\n",
        "}\n",
        "exp_df2 = experiment(dataset_name=dataset_name,model_names=model_names, model_params=model_params, data=data, x_types=noise_var_names_feat_exp, \n",
        "           edge_types=['edge_index'], noise_info=noise_info, num_epochs=25, repeat_num=3, print_updates=True)\n",
        "\n",
        "exp_df2"
      ],
      "metadata": {
        "id": "d5sxU0Z-89RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noise data creation example: remove edges -- strategy 1: from all edges\n",
        "\n",
        "remove_edge_params = {'edge_index':data.edge_index, 'remove_bidirectional':True}\n",
        "noise_info = {'noise_type':'edge_removal', 'strategy':'all_edges', 'params':remove_edge_params, \n",
        "              'noise_levels':[0, 0.3, 0.6, 0.9 ], 'noise_param_name':'edges_to_remove_ratio'}\n",
        "\n",
        "exp3_edge_var_names = create_noised_data_for_experiment(data=data, noise_info=noise_info)\n",
        "print(data)\n",
        "\n",
        "\n",
        "# Experiment on edge removal - strategy-all edges\n",
        "model_names = ['GNN', 'Graphsage']\n",
        "model_params = {  # TODO random params change later\n",
        "    'GNN':{'in_channels':1433, 'hidden_channels':16, 'out_channels':7, 'num_layers':3, 'dropout':0.1},\n",
        "    'GAT':{'in_channels':1433, 'hidden_channels':12, 'out_channels':7, 'num_layers':3, 'dropout':0.2},\n",
        "    'Graphsage':{'in_channels':1433, 'hidden_channels':14, 'out_channels':7, 'num_layers':3, 'dropout':0.1}\n",
        "}\n",
        "exp_df3 = experiment(dataset_name=dataset_name,model_names=model_names, model_params=model_params, data=data, x_types=['x'], \n",
        "           edge_types=exp3_edge_var_names, noise_info=noise_info, num_epochs=25, repeat_num=3, print_updates=True)\n",
        "\n",
        "exp_df3"
      ],
      "metadata": {
        "id": "debyLU-m8ZxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7IpcS0718eb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f824h7qwNizp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}