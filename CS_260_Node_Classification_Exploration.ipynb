{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS 260 Node Classification Exploration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1op-CbyLuN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad817c5-9dae-460e-897e-b65ecdad931c"
      },
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize(h, color):\n",
        "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 34.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.6 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "from torch_geometric.utils import degree\n",
        "import torch_geometric\n",
        "import torch_geometric.utils as tg_utils"
      ],
      "metadata": {
        "id": "5zzyCFITsi1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XbHNyORvbNu",
        "outputId": "e3dde74a-9492-4537-bb2b-3b019b2d93e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imGrKO5YH11-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83132edf-0015-47ee-813e-19a967e3a197"
      },
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: Cora():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "\n",
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
            "===========================================================================================================\n",
            "Number of nodes: 2708\n",
            "Number of edges: 10556\n",
            "Average node degree: 3.90\n",
            "Number of training nodes: 140\n",
            "Training node label rate: 0.05\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjczKOknxmZ6",
        "outputId": "fc9598de-7aaa-4c1e-9a7d-8fefe1ae0b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s17HUi5txtYd",
        "outputId": "4528c1b3-6ca1-409b-e047-405363728798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WrQIZpnxtkZ",
        "outputId": "b1e0e1b8-9672-4672-f4e2-b53a90ac1446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
              "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros(data.x.shape)\n",
        "ones = torch.ones(data.x.shape)\n",
        "\n",
        "noise = (0.1**0.5)*torch.randn(data.x.shape)\n",
        "print(noise.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IBAkLu2wrNo",
        "outputId": "f58fea5c-d325-4af4-e083-e8acc8abf4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2708, 1433])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_masked_noise(x,  noise_level=0.15):\n",
        "  noise_added_node_num = int(noise_level * x.shape[0])\n",
        "  chose_random_rows = np.random.choice(x.shape[0], noise_added_node_num, replace=False)\n",
        "  #print(chose_random_rows)\n",
        "  mask_rows = torch.zeros(x.shape)\n",
        "  mask_rows[chose_random_rows,:] = torch.ones(1, x.shape[1])\n",
        "  noise = (0.1**0.5)*torch.randn(x.shape)\n",
        "  masked_noise = noise* mask_rows.int().float()\n",
        "\n",
        "  #print(mask_rows)\n",
        "  #print(noise)\n",
        "  #print(masked_noise)\n",
        "  return masked_noise"
      ],
      "metadata": {
        "id": "W45Hs6203FyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_noisy = data\n",
        "data.x_noisy = data.x + noise\n",
        "data.x_zeros = zeros\n",
        "data.x_ones = ones\n",
        "\n",
        "for noise_level in [0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99]:\n",
        "  masked_noise = get_masked_noise(x=data.x,  noise_level=noise_level)\n",
        "  data[f'x_noisy_n_{noise_level}'] = data.x + masked_noise"
      ],
      "metadata": {
        "id": "TKxSBOCeqSK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 15% noise over all features\n",
        "mask = torch.randn((3, 5)) < 0.15\n",
        "noise = (0.1**0.5)*torch.randn(3,5)\n",
        "masked_noise = noise* mask.int().float()\n",
        "\n",
        "print(mask)\n",
        "print(noise)\n",
        "print(masked_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTTeLDepx2hh",
        "outputId": "bd21274a-13a9-40da-e7ba-465c47c5b412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False,  True,  True,  True, False],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [False, False,  True, False, False]])\n",
            "tensor([[ 0.0044, -0.1506,  0.0560,  0.2462, -0.1118],\n",
            "        [ 0.1300,  0.1887, -0.2272,  0.0604,  0.1066],\n",
            "        [-0.4169, -0.1230,  0.2110, -0.2359,  0.1089]])\n",
            "tensor([[ 0.0000, -0.1506,  0.0560,  0.2462, -0.0000],\n",
            "        [ 0.1300,  0.1887, -0.2272,  0.0604,  0.1066],\n",
            "        [-0.0000, -0.0000,  0.2110, -0.0000,  0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add noise on 15% of nodes\n",
        "chose_random_rows = np.random.choice(5, 2, replace=False)\n",
        "print(chose_random_rows)\n",
        "mask_rows = torch.zeros((5,3))\n",
        "mask_rows[chose_random_rows,:] = torch.ones(1, 3)\n",
        "noise = (0.1**0.5)*torch.randn(5,3)\n",
        "masked_noise = noise* mask_rows.int().float()\n",
        "\n",
        "print(mask_rows)\n",
        "print(noise)\n",
        "print(masked_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqWXBDdk0BCj",
        "outputId": "d557fa11-166c-41bd-e7f3-206a6c0bd2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4]\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[ 0.3682, -0.0298,  0.1962],\n",
            "        [-0.3538,  0.1212, -0.0716],\n",
            "        [-0.2377,  0.4975,  0.2494],\n",
            "        [ 0.3457, -0.2733, -0.4690],\n",
            "        [-0.4664,  0.2792, -0.2998]])\n",
            "tensor([[ 0.0000, -0.0000,  0.0000],\n",
            "        [-0.0000,  0.0000, -0.0000],\n",
            "        [-0.0000,  0.0000,  0.0000],\n",
            "        [ 0.3457, -0.2733, -0.4690],\n",
            "        [-0.4664,  0.2792, -0.2998]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IRdAELVKOl6"
      },
      "source": [
        "## Training a Multi-layer Perception Network (MLP)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afXwPCA3KNoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a120ea18-5245-4b1d-ce1e-b76dc7c0b665"
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.lin1 = Linear(dataset.num_features, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP(hidden_channels=16)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (lin1): Linear(in_features=1433, out_features=16, bias=True)\n",
            "  (lin2): Linear(in_features=16, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YgHcLXMLk4o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e5b311ce-25b0-4836-d8c0-bc084a2a2039"
      },
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "model = MLP(hidden_channels=16)\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n",
        "\n",
        "def train( x_type='x'):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      out = model(data[x_type])  # Perform a single forward pass.\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      return loss\n",
        "\n",
        "def test( x_type='x'):\n",
        "      model.eval()\n",
        "      out = model(data[x_type])\n",
        "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
        "      return test_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = MLP(hidden_channels=16)\n",
        "x_type='x'\n",
        "for epoch in range(1, 201):\n",
        "    loss = train(x_type=x_type)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "test_acc = test(x_type=x_type)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDB20bdlt5-g",
        "outputId": "45226104-6979-4a3e-f83f-0ec737e0d06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 1.9615\n",
            "Epoch: 002, Loss: 1.9557\n",
            "Epoch: 003, Loss: 1.9505\n",
            "Epoch: 004, Loss: 1.9423\n",
            "Epoch: 005, Loss: 1.9327\n",
            "Epoch: 006, Loss: 1.9279\n",
            "Epoch: 007, Loss: 1.9144\n",
            "Epoch: 008, Loss: 1.9087\n",
            "Epoch: 009, Loss: 1.9023\n",
            "Epoch: 010, Loss: 1.8893\n",
            "Epoch: 011, Loss: 1.8776\n",
            "Epoch: 012, Loss: 1.8594\n",
            "Epoch: 013, Loss: 1.8457\n",
            "Epoch: 014, Loss: 1.8365\n",
            "Epoch: 015, Loss: 1.8280\n",
            "Epoch: 016, Loss: 1.7965\n",
            "Epoch: 017, Loss: 1.7984\n",
            "Epoch: 018, Loss: 1.7832\n",
            "Epoch: 019, Loss: 1.7495\n",
            "Epoch: 020, Loss: 1.7441\n",
            "Epoch: 021, Loss: 1.7188\n",
            "Epoch: 022, Loss: 1.7124\n",
            "Epoch: 023, Loss: 1.6785\n",
            "Epoch: 024, Loss: 1.6660\n",
            "Epoch: 025, Loss: 1.6119\n",
            "Epoch: 026, Loss: 1.6236\n",
            "Epoch: 027, Loss: 1.5827\n",
            "Epoch: 028, Loss: 1.5784\n",
            "Epoch: 029, Loss: 1.5524\n",
            "Epoch: 030, Loss: 1.5020\n",
            "Epoch: 031, Loss: 1.5065\n",
            "Epoch: 032, Loss: 1.4742\n",
            "Epoch: 033, Loss: 1.4581\n",
            "Epoch: 034, Loss: 1.4246\n",
            "Epoch: 035, Loss: 1.4131\n",
            "Epoch: 036, Loss: 1.4112\n",
            "Epoch: 037, Loss: 1.3923\n",
            "Epoch: 038, Loss: 1.3055\n",
            "Epoch: 039, Loss: 1.2982\n",
            "Epoch: 040, Loss: 1.2543\n",
            "Epoch: 041, Loss: 1.2244\n",
            "Epoch: 042, Loss: 1.2331\n",
            "Epoch: 043, Loss: 1.1984\n",
            "Epoch: 044, Loss: 1.1796\n",
            "Epoch: 045, Loss: 1.1093\n",
            "Epoch: 046, Loss: 1.1284\n",
            "Epoch: 047, Loss: 1.1229\n",
            "Epoch: 048, Loss: 1.0383\n",
            "Epoch: 049, Loss: 1.0439\n",
            "Epoch: 050, Loss: 1.0563\n",
            "Epoch: 051, Loss: 0.9893\n",
            "Epoch: 052, Loss: 1.0508\n",
            "Epoch: 053, Loss: 0.9343\n",
            "Epoch: 054, Loss: 0.9639\n",
            "Epoch: 055, Loss: 0.8929\n",
            "Epoch: 056, Loss: 0.8705\n",
            "Epoch: 057, Loss: 0.9176\n",
            "Epoch: 058, Loss: 0.9239\n",
            "Epoch: 059, Loss: 0.8641\n",
            "Epoch: 060, Loss: 0.8578\n",
            "Epoch: 061, Loss: 0.7908\n",
            "Epoch: 062, Loss: 0.7856\n",
            "Epoch: 063, Loss: 0.7683\n",
            "Epoch: 064, Loss: 0.7816\n",
            "Epoch: 065, Loss: 0.7356\n",
            "Epoch: 066, Loss: 0.6951\n",
            "Epoch: 067, Loss: 0.7300\n",
            "Epoch: 068, Loss: 0.6939\n",
            "Epoch: 069, Loss: 0.7550\n",
            "Epoch: 070, Loss: 0.6864\n",
            "Epoch: 071, Loss: 0.7094\n",
            "Epoch: 072, Loss: 0.7238\n",
            "Epoch: 073, Loss: 0.7150\n",
            "Epoch: 074, Loss: 0.6191\n",
            "Epoch: 075, Loss: 0.6770\n",
            "Epoch: 076, Loss: 0.6487\n",
            "Epoch: 077, Loss: 0.6258\n",
            "Epoch: 078, Loss: 0.5821\n",
            "Epoch: 079, Loss: 0.5637\n",
            "Epoch: 080, Loss: 0.6368\n",
            "Epoch: 081, Loss: 0.6333\n",
            "Epoch: 082, Loss: 0.6434\n",
            "Epoch: 083, Loss: 0.5974\n",
            "Epoch: 084, Loss: 0.6176\n",
            "Epoch: 085, Loss: 0.5972\n",
            "Epoch: 086, Loss: 0.4690\n",
            "Epoch: 087, Loss: 0.6362\n",
            "Epoch: 088, Loss: 0.6118\n",
            "Epoch: 089, Loss: 0.5248\n",
            "Epoch: 090, Loss: 0.5520\n",
            "Epoch: 091, Loss: 0.6130\n",
            "Epoch: 092, Loss: 0.5361\n",
            "Epoch: 093, Loss: 0.5594\n",
            "Epoch: 094, Loss: 0.5049\n",
            "Epoch: 095, Loss: 0.5043\n",
            "Epoch: 096, Loss: 0.5235\n",
            "Epoch: 097, Loss: 0.5451\n",
            "Epoch: 098, Loss: 0.5329\n",
            "Epoch: 099, Loss: 0.5008\n",
            "Epoch: 100, Loss: 0.5350\n",
            "Epoch: 101, Loss: 0.5343\n",
            "Epoch: 102, Loss: 0.5138\n",
            "Epoch: 103, Loss: 0.5377\n",
            "Epoch: 104, Loss: 0.5353\n",
            "Epoch: 105, Loss: 0.5176\n",
            "Epoch: 106, Loss: 0.5229\n",
            "Epoch: 107, Loss: 0.4558\n",
            "Epoch: 108, Loss: 0.4883\n",
            "Epoch: 109, Loss: 0.4659\n",
            "Epoch: 110, Loss: 0.4908\n",
            "Epoch: 111, Loss: 0.4966\n",
            "Epoch: 112, Loss: 0.4725\n",
            "Epoch: 113, Loss: 0.4787\n",
            "Epoch: 114, Loss: 0.4390\n",
            "Epoch: 115, Loss: 0.4199\n",
            "Epoch: 116, Loss: 0.4810\n",
            "Epoch: 117, Loss: 0.4484\n",
            "Epoch: 118, Loss: 0.5080\n",
            "Epoch: 119, Loss: 0.4241\n",
            "Epoch: 120, Loss: 0.4745\n",
            "Epoch: 121, Loss: 0.4651\n",
            "Epoch: 122, Loss: 0.4652\n",
            "Epoch: 123, Loss: 0.5580\n",
            "Epoch: 124, Loss: 0.4861\n",
            "Epoch: 125, Loss: 0.4405\n",
            "Epoch: 126, Loss: 0.4292\n",
            "Epoch: 127, Loss: 0.4409\n",
            "Epoch: 128, Loss: 0.3575\n",
            "Epoch: 129, Loss: 0.4468\n",
            "Epoch: 130, Loss: 0.4603\n",
            "Epoch: 131, Loss: 0.4108\n",
            "Epoch: 132, Loss: 0.4601\n",
            "Epoch: 133, Loss: 0.4258\n",
            "Epoch: 134, Loss: 0.3852\n",
            "Epoch: 135, Loss: 0.4028\n",
            "Epoch: 136, Loss: 0.4245\n",
            "Epoch: 137, Loss: 0.4300\n",
            "Epoch: 138, Loss: 0.4693\n",
            "Epoch: 139, Loss: 0.4314\n",
            "Epoch: 140, Loss: 0.4031\n",
            "Epoch: 141, Loss: 0.4290\n",
            "Epoch: 142, Loss: 0.4110\n",
            "Epoch: 143, Loss: 0.3863\n",
            "Epoch: 144, Loss: 0.4215\n",
            "Epoch: 145, Loss: 0.4519\n",
            "Epoch: 146, Loss: 0.3940\n",
            "Epoch: 147, Loss: 0.4429\n",
            "Epoch: 148, Loss: 0.3527\n",
            "Epoch: 149, Loss: 0.4390\n",
            "Epoch: 150, Loss: 0.4212\n",
            "Epoch: 151, Loss: 0.4128\n",
            "Epoch: 152, Loss: 0.3779\n",
            "Epoch: 153, Loss: 0.4801\n",
            "Epoch: 154, Loss: 0.4130\n",
            "Epoch: 155, Loss: 0.3962\n",
            "Epoch: 156, Loss: 0.4262\n",
            "Epoch: 157, Loss: 0.4210\n",
            "Epoch: 158, Loss: 0.4081\n",
            "Epoch: 159, Loss: 0.4066\n",
            "Epoch: 160, Loss: 0.3782\n",
            "Epoch: 161, Loss: 0.3836\n",
            "Epoch: 162, Loss: 0.4172\n",
            "Epoch: 163, Loss: 0.3993\n",
            "Epoch: 164, Loss: 0.4477\n",
            "Epoch: 165, Loss: 0.3714\n",
            "Epoch: 166, Loss: 0.3610\n",
            "Epoch: 167, Loss: 0.4546\n",
            "Epoch: 168, Loss: 0.4387\n",
            "Epoch: 169, Loss: 0.3793\n",
            "Epoch: 170, Loss: 0.3704\n",
            "Epoch: 171, Loss: 0.4286\n",
            "Epoch: 172, Loss: 0.4131\n",
            "Epoch: 173, Loss: 0.3795\n",
            "Epoch: 174, Loss: 0.4230\n",
            "Epoch: 175, Loss: 0.4139\n",
            "Epoch: 176, Loss: 0.3586\n",
            "Epoch: 177, Loss: 0.3588\n",
            "Epoch: 178, Loss: 0.3911\n",
            "Epoch: 179, Loss: 0.3810\n",
            "Epoch: 180, Loss: 0.4203\n",
            "Epoch: 181, Loss: 0.3583\n",
            "Epoch: 182, Loss: 0.3690\n",
            "Epoch: 183, Loss: 0.4025\n",
            "Epoch: 184, Loss: 0.3920\n",
            "Epoch: 185, Loss: 0.4369\n",
            "Epoch: 186, Loss: 0.4317\n",
            "Epoch: 187, Loss: 0.4911\n",
            "Epoch: 188, Loss: 0.3369\n",
            "Epoch: 189, Loss: 0.4945\n",
            "Epoch: 190, Loss: 0.3912\n",
            "Epoch: 191, Loss: 0.3824\n",
            "Epoch: 192, Loss: 0.3479\n",
            "Epoch: 193, Loss: 0.3798\n",
            "Epoch: 194, Loss: 0.3799\n",
            "Epoch: 195, Loss: 0.4015\n",
            "Epoch: 196, Loss: 0.3615\n",
            "Epoch: 197, Loss: 0.3985\n",
            "Epoch: 198, Loss: 0.4664\n",
            "Epoch: 199, Loss: 0.3714\n",
            "Epoch: 200, Loss: 0.3810\n",
            "Test Accuracy: 0.5900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP different X features noise levels"
      ],
      "metadata": {
        "id": "Aa3SpMMG89Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_levels = [0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99]\n",
        "x_noises =[f'x_noisy_n_{x}' for x in noise_levels ]\n",
        "\n",
        "x_types=['x', 'x_noisy', 'x_ones'] +x_noises\n",
        "for x_type in x_types:\n",
        "  #model = MLP(hidden_channels=16)\n",
        "  for epoch in range(1, 201):\n",
        "      loss = train(x_type=x_type)\n",
        "      #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "  test_acc = test(x_type=x_type)\n",
        "  print(f'{x_type} Test Accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_zyqx1z8bSU",
        "outputId": "e004833a-a914-4d24-a3c4-6ebd38d65293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x Test Accuracy: 0.6000\n",
            "x_noisy Test Accuracy: 0.2100\n",
            "x_ones Test Accuracy: 0.0640\n",
            "x_noisy_n_0.15 Test Accuracy: 0.5250\n",
            "x_noisy_n_0.3 Test Accuracy: 0.4560\n",
            "x_noisy_n_0.45 Test Accuracy: 0.3890\n",
            "x_noisy_n_0.6 Test Accuracy: 0.3370\n",
            "x_noisy_n_0.9 Test Accuracy: 0.1980\n",
            "x_noisy_n_0.95 Test Accuracy: 0.1860\n",
            "x_noisy_n_0.99 Test Accuracy: 0.1640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN"
      ],
      "metadata": {
        "id": "u6ha4d_w9CQR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmXWs1dKIzD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1dfdccc-23c8-4f8d-9272-3a22f83b7240"
      },
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(1234567)\n",
        "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=16)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(1433, 16)\n",
            "  (conv2): GCNConv(16, 7)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3TAi69zI1bO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a86ba75e-737d-464c-e194-eb189bf4a683"
      },
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "model = GCN(hidden_channels=16)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train(x_type='x', edge_type='edge_index'):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      out = model(data[x_type], data[edge_type])  # Perform a single forward pass.\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      return loss\n",
        "\n",
        "def test(x_type='x', edge_type='edge_index'):\n",
        "      model.eval()\n",
        "      out = model(data[x_type], data[edge_type])\n",
        "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
        "      return test_acc\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN different X features noise levels"
      ],
      "metadata": {
        "id": "16hN7hJ780t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_levels = [0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99]\n",
        "x_noises =[f'x_noisy_n_{x}' for x in noise_levels ]\n",
        "\n",
        "x_types=['x', 'x_noisy', 'x_ones'] +x_noises\n",
        "for x_type in x_types:\n",
        "  #model = GCN(hidden_channels=16)\n",
        "  for epoch in range(1, 101):\n",
        "      loss = train(x_type=x_type)\n",
        "      #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "  test_acc = test(x_type=x_type)\n",
        "  print(f'{x_type} Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrXnf8OtwSX7",
        "outputId": "a2e2e56b-0483-4181-eced-f0c5b60c5d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x Test Accuracy: 0.8150\n",
            "x_noisy Test Accuracy: 0.4700\n",
            "x_ones Test Accuracy: 0.3190\n",
            "x_noisy_n_0.15 Test Accuracy: 0.5410\n",
            "x_noisy_n_0.3 Test Accuracy: 0.4510\n",
            "x_noisy_n_0.45 Test Accuracy: 0.4090\n",
            "x_noisy_n_0.6 Test Accuracy: 0.3590\n",
            "x_noisy_n_0.9 Test Accuracy: 0.4000\n",
            "x_noisy_n_0.95 Test Accuracy: 0.3400\n",
            "x_noisy_n_0.99 Test Accuracy: 0.3680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove x% edges\n",
        "def remove_from_all_edges(edge_index, edges_to_remove_ratio = 0.15):\n",
        "  edges_to_remove_ratio = 0.15\n",
        "  edge_ratio_to_keep = 1 - edges_to_remove_ratio\n",
        "  num_edges_keep= int(edge_ratio_to_keep * edge_index.shape[1])\n",
        "  chose_random_edge_indices = np.random.choice(edge_index.shape[1], num_edges_keep, replace=False)\n",
        "\n",
        "  print(edge_index[0][chose_random_edge_indices].shape)\n",
        "  print(num_edges_keep)\n",
        "  print(edge_index.shape[1])\n",
        "\n",
        "  edge_index_removed = torch.zeros((2,num_edges_keep), dtype=torch.int64)\n",
        "  edge_index_removed[0] = edge_index[0][chose_random_edge_indices]\n",
        "  edge_index_removed[1] = edge_index[1][chose_random_edge_indices]\n",
        "  return edge_index_removed\n",
        "\n",
        "edge_index_removed = remove_from_all_edges(edge_index=data.edge_index, edges_to_remove_ratio = 0.15)\n",
        "data.edge_index_85 = edge_index_removed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpEb0WU4CDR8",
        "outputId": "80649403-3b8a-42e3-f433-16a2fde77d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8972])\n",
            "8972\n",
            "10556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ed_type = 'edge_index_85'\n",
        "noise_levels = [0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99]\n",
        "x_noises =[f'x_noisy_n_{x}' for x in noise_levels ]\n",
        "\n",
        "x_types=['x', 'x_noisy', 'x_ones'] +x_noises\n",
        "for x_type in x_types:\n",
        "  #model = GCN(hidden_channels=16)\n",
        "  for epoch in range(1, 101):\n",
        "      loss = train(x_type=x_type, edge_type=ed_type)\n",
        "      #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "  test_acc = test(x_type=x_type,edge_type=ed_type)\n",
        "  print(f'{x_type} Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAOqlGSmFZy2",
        "outputId": "87199d1e-792f-4b57-8225-d0939abfb091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x Test Accuracy: 0.7100\n",
            "x_noisy Test Accuracy: 0.4200\n",
            "x_ones Test Accuracy: 0.1440\n",
            "x_noisy_n_0.15 Test Accuracy: 0.5360\n",
            "x_noisy_n_0.3 Test Accuracy: 0.4940\n",
            "x_noisy_n_0.45 Test Accuracy: 0.4700\n",
            "x_noisy_n_0.6 Test Accuracy: 0.4110\n",
            "x_noisy_n_0.9 Test Accuracy: 0.3910\n",
            "x_noisy_n_0.95 Test Accuracy: 0.3600\n",
            "x_noisy_n_0.99 Test Accuracy: 0.3950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove x% edges from random k, top_k, bottom_k nodes\n",
        "\n",
        "def choose_nodes_to_remove_from(data, num_nodes, k_nodes, remove_type):\n",
        "  if remove_type=='random':\n",
        "    nodes_chosen = torch.tensor([np.random.choice(num_nodes, k_nodes, replace=False)])\n",
        "  elif remove_type=='top_k':\n",
        "    # find indegree edges\n",
        "    dg = torch_geometric.utils.degree(data.edge_index[0])\n",
        "    top_k_nodes_degrees, top_k_nodes_indices = torch.topk(dg, k_nodes)\n",
        "    #print(top_k_nodes_degrees, top_k_nodes_indices)\n",
        "    nodes_chosen = top_k_nodes_indices\n",
        "  elif remove_type=='bottom_k':\n",
        "    # find indegree edges\n",
        "    dg = torch_geometric.utils.degree(data.edge_index[0])\n",
        "    bottom_k_nodes_degrees, bottom_k_nodes_indices = torch.topk(dg, k_nodes, largest=False)\n",
        "    #print(bottom_k_nodes_degrees, bottom_k_nodes_indices)\n",
        "    nodes_chosen = bottom_k_nodes_indices\n",
        "  else:\n",
        "    raise 'remove_type should be from random, top_k, bottom_k'\n",
        "  return nodes_chosen\n",
        "\n",
        "# to do loop for each node separately\n",
        "def remove_edges_from_chosen_nodes(data, nodes_chosen, edges_to_remove_per_node_ratio, remove_bidirectional):\n",
        "  edges_0_list, edges_1_list = [],[]\n",
        "  for nc in nodes_chosen:\n",
        "    edge_0, edge_1 = remove_edge_per_node(data=data, node=nc, \n",
        "                                          edges_to_remove_per_node_ratio=edges_to_remove_per_node_ratio, \n",
        "                                          remove_bidirectional=remove_bidirectional)\n",
        "    edges_0_list.append(edge_0)\n",
        "    edges_1_list.append(edge_1)\n",
        "\n",
        "  edges_0 = torch.cat(edges_0_list, 0)\n",
        "  edges_1 = torch.cat(edges_1_list, 0)\n",
        "  return edges_0, edges_1\n",
        "\n",
        "def remove_edge_per_node(data, node, edges_to_remove_per_node_ratio=0.1, remove_bidirectional=False):\n",
        "  mask_node_indices = torch.isin(data.edge_index[0], node)\n",
        "\n",
        "  select_node_edges_0 = data.edge_index[0][mask_node_indices]\n",
        "  select_node_edges_1 = data.edge_index[1][mask_node_indices]\n",
        "  #print(select_node_edges_0)\n",
        "  #print(select_node_edges_1)\n",
        "\n",
        "  # choose how much of the edges we will remove for this node\n",
        "  # we decide on number of edges to remove for each node based on the number of edges each node has\n",
        "  # and by taking the ratio given by edges_to_remove_per_node_ratio\n",
        "  # note: we use ceil to remove at least one node (unless ratio is 0)\n",
        "  num_edges_remove = int(math.ceil(edges_to_remove_per_node_ratio* select_node_edges_0.shape[0]))\n",
        "  #print(num_edges_remove)\n",
        "  num_edges_keep = select_node_edges_0.shape[0] - num_edges_remove\n",
        "\n",
        "  # choose random edges to keep, the rest is removed\n",
        "  chose_random_edge_indices = np.random.choice( select_node_edges_0.shape[0], num_edges_keep, replace=False)\n",
        "  #print(num_edges_keep)\n",
        "  \n",
        "  if remove_bidirectional:\n",
        "    mask_node_indices_2 = torch.isin(data.edge_index[1], node)\n",
        "    # find the node names deleted in below indices and delete also for the opposite side.\n",
        "    raise 'You haven\\'t implemented remove bidirectional yet!'\n",
        "\n",
        "  edge_index_removed = torch.zeros((2,num_edges_keep), dtype=torch.int64)\n",
        "  edge_node_index_removed_0 = select_node_edges_0[chose_random_edge_indices]\n",
        "  edge_node_index_removed_1 = select_node_edges_1[chose_random_edge_indices]\n",
        "\n",
        "  return edge_node_index_removed_0, edge_node_index_removed_1\n",
        "\n",
        "def remove_edges_from_nodes(data, edges_to_remove_per_node_ratio = 0.15, k_nodes=10,\n",
        "                            remove_type='random', remove_bidirectional=False):\n",
        "  edges_to_remove_per_node_ratio = 0.15\n",
        "  edge_p_node_ratio_to_keep = 1 - edges_to_remove_per_node_ratio\n",
        "\n",
        "  # choose topk, bottomk, or random\n",
        "  nodes_chosen = choose_nodes_to_remove_from(data=data, num_nodes=data.num_nodes, k_nodes=k_nodes, remove_type=remove_type)\n",
        "\n",
        "  # keep edges from remaining nodes\n",
        "  mask_node_indices = torch.isin(data.edge_index[0],nodes_chosen)\n",
        "  index_keep = torch.ones(data.edge_index[0].shape[0], dtype=bool)\n",
        "  index_keep[mask_node_indices] = False\n",
        "  edges_to_keep_0 = data.edge_index[0][index_keep]\n",
        "  edges_to_keep_1 = data.edge_index[1][index_keep]\n",
        "  print(edges_to_keep_0) \n",
        "  print(edges_to_keep_1)\n",
        "\n",
        "  # remove one-directional or bi-directional\n",
        "  edges_0_kept_chosen_nodes, edges_1_kept_chosen_nodes = remove_edges_from_chosen_nodes(data, nodes_chosen, edges_to_remove_per_node_ratio, remove_bidirectional)\n",
        "\n",
        "  # concat edges to keep and edges_kept_chosen_nodes\n",
        "  final_edges_0 = torch.cat([edges_to_keep_0, edges_0_kept_chosen_nodes], 0)\n",
        "  final_edges_1 = torch.cat([edges_to_keep_1, edges_1_kept_chosen_nodes], 0)\n",
        "\n",
        "  edge_index_removed = torch.zeros((2, final_edges_0.shape[0]), dtype=torch.int64)\n",
        "  edge_index_removed[0] = final_edges_0\n",
        "  edge_index_removed[1] = final_edges_1\n",
        "\n",
        "  # use TORCH_GEOMETRIC.UTILS.SORT_EDGE_INDEX\n",
        "  edge_index_removed_sorted = tg_utils.sort_edge_index(edge_index_removed)\n",
        "  return edge_index_removed_sorted\n"
      ],
      "metadata": {
        "id": "0WSp747oA8MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = remove_edges_from_nodes(data=data, edges_to_remove_per_node_ratio = 0.5, k_nodes=1000,\n",
        "                            remove_type='random', remove_bidirectional=False)\n",
        "\n",
        "edges.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja4XxaDHA2db",
        "outputId": "e3f8102e-dd2d-4e5b-a8ef-ce2ab4ffb7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   2,    2,    2,  ..., 2707, 2707, 2707])\n",
            "tensor([   1,  332, 1454,  ...,  598, 1473, 2706])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9988])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges = remove_edges_from_nodes(data=data, edges_to_remove_per_node_ratio = 0.5, k_nodes=1000,\n",
        "                            remove_type='top_k', remove_bidirectional=False)\n",
        "edges.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa31gFOl4w9v",
        "outputId": "2822559c-576d-4f83-9620-8a643e496c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   0,    0,    0,  ..., 2703, 2704, 2705])\n",
            "tensor([ 633, 1862, 2582,  ..., 1298,  641,  287])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9124])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.edge_index[0][:10])\n",
        "data.edge_index[1][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAGFHTa7YI0X",
        "outputId": "fcec2640-115a-4a91-d68b-786afd0630be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1, 1, 2, 2, 2, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 633, 1862, 2582,    2,  652,  654,    1,  332, 1454, 1666])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm = torch.isin(data.edge_index[0], 1862)\n",
        "data.edge_index[1][mm]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qElNwtWDYOf7",
        "outputId": "fa5847d1-d2af-4e4c-b676-ec6cef0a6532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0,  926, 1701, 2582])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODOs:\n",
        "# TODO remove bidirectional\n",
        "\n",
        "# TODO add edges:\n",
        "  # TODO add random edges\n",
        "  # TODO add edges to top k node \n",
        "  # TODO add edges to bottom k node \n",
        "  # TODO add edges to random k node \n",
        "\n",
        "# decide on experiments\n",
        "# experiments/research questions\n",
        "# decide on datasets\n",
        "# decide models to use (mlp, gnn, graphsage, ??)\n",
        "# decide on what to log, save, how to design experiments \n",
        "# reliability of experiments: 10 experiments and avg results (log each experiment)\n",
        "# Run each experiment\n",
        "# plots for experiments"
      ],
      "metadata": {
        "id": "841jfXxUTrMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}