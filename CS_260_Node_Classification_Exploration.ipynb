{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS_260_Node_Classification_Exploration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camligorkem/cs-260c-project/blob/main/CS_260_Node_Classification_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1op-CbyLuN4"
      },
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize(h, color):\n",
        "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    plt.show()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "from torch_geometric.utils import degree\n",
        "import torch_geometric\n",
        "import torch_geometric.utils as tg_utils"
      ],
      "metadata": {
        "id": "5zzyCFITsi1f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XbHNyORvbNu",
        "outputId": "3ebd44b2-5f8c-4331-b6cc-74b876093777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imGrKO5YH11-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec593f52-51c3-4185-a2a7-364f0a7ba5ae"
      },
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: Cora():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "\n",
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
            "===========================================================================================================\n",
            "Number of nodes: 2708\n",
            "Number of edges: 10556\n",
            "Average node degree: 3.90\n",
            "Number of training nodes: 140\n",
            "Training node label rate: 0.05\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros(data.x.shape)\n",
        "ones = torch.ones(data.x.shape)\n",
        "\n",
        "noise = (0.1**0.5)*torch.randn(data.x.shape)\n",
        "print(noise.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IBAkLu2wrNo",
        "outputId": "7f9fe32e-2116-4060-e213-65021b2b7f80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2708, 1433])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_masked_noise(x,  noise_level=0.15):\n",
        "  noise_added_node_num = int(noise_level * x.shape[0])\n",
        "  chose_random_rows = np.random.choice(x.shape[0], noise_added_node_num, replace=False)\n",
        "  #print(chose_random_rows)\n",
        "  mask_rows = torch.zeros(x.shape)\n",
        "  mask_rows[chose_random_rows,:] = torch.ones(1, x.shape[1])\n",
        "  noise = (0.1**0.5)*torch.randn(x.shape)\n",
        "  masked_noise = noise* mask_rows.int().float()\n",
        "\n",
        "  #print(mask_rows)\n",
        "  #print(noise)\n",
        "  #print(masked_noise)\n",
        "  return masked_noise"
      ],
      "metadata": {
        "id": "W45Hs6203FyL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_noisy = data\n",
        "data.x_noisy = data.x + noise\n",
        "data.x_zeros = zeros\n",
        "data.x_ones = ones\n",
        "\n",
        "for noise_level in [0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99]:\n",
        "  masked_noise = get_masked_noise(x=data.x,  noise_level=noise_level)\n",
        "  data[f'x_noisy_n_{noise_level}'] = data.x + masked_noise"
      ],
      "metadata": {
        "id": "TKxSBOCeqSK2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IRdAELVKOl6"
      },
      "source": [
        "## Training a Multi-layer Perception Network (MLP)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afXwPCA3KNoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e621b444-49bf-4246-b5e5-68e1c6971315"
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.lin1 = Linear(dataset.num_features, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP(hidden_channels=16)\n",
        "print(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (lin1): Linear(in_features=1433, out_features=16, bias=True)\n",
            "  (lin2): Linear(in_features=16, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YgHcLXMLk4o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f24a0dfa-efd0-46e4-f784-33fa26c3892a"
      },
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
        "\n",
        "def train(model, optimizer, x_type='x'):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      out = model(data[x_type])  # Perform a single forward pass.\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      return loss\n",
        "\n",
        "def test(model, x_type='x'):\n",
        "      model.eval()\n",
        "      out = model(data[x_type])\n",
        "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
        "      return test_acc"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_type='x'\n",
        "model = MLP(hidden_channels=16)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "  \n",
        "for epoch in range(1, 201):\n",
        "    loss = train(model, optimizer, x_type=x_type)\n",
        "    #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "test_acc = test(model, x_type=x_type)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDB20bdlt5-g",
        "outputId": "20aa09f3-88b7-4062-c38e-5960e6f5dfb9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP different X features noise levels"
      ],
      "metadata": {
        "id": "Aa3SpMMG89Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_levels = [0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99]\n",
        "x_noises =[f'x_noisy_n_{x}' for x in noise_levels ]\n",
        "\n",
        "x_types=['x', 'x_noisy', 'x_ones'] +x_noises+['x']\n",
        "for x_type in x_types:\n",
        "  model = MLP(hidden_channels=16)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n",
        "  for epoch in range(1, 201):\n",
        "      loss = train(model, optimizer, x_type=x_type)\n",
        "      #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "  test_acc = test(model, x_type=x_type)\n",
        "  print(f'{x_type} Test Accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_zyqx1z8bSU",
        "outputId": "f6ac5798-d628-4ad9-ce4f-a719d8ec38b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x Test Accuracy: 0.5900\n",
            "x_noisy Test Accuracy: 0.1490\n",
            "x_ones Test Accuracy: 0.0640\n",
            "x_noisy_n_0.15 Test Accuracy: 0.5250\n",
            "x_noisy_n_0.3 Test Accuracy: 0.4170\n",
            "x_noisy_n_0.45 Test Accuracy: 0.3320\n",
            "x_noisy_n_0.6 Test Accuracy: 0.3090\n",
            "x_noisy_n_0.9 Test Accuracy: 0.1810\n",
            "x_noisy_n_0.95 Test Accuracy: 0.1360\n",
            "x_noisy_n_0.99 Test Accuracy: 0.1530\n",
            "x Test Accuracy: 0.5900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN"
      ],
      "metadata": {
        "id": "u6ha4d_w9CQR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmXWs1dKIzD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3dece8c-e8c7-4442-bd3b-e384d357c445"
      },
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(1234567)\n",
        "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=16)\n",
        "print(model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(1433, 16)\n",
            "  (conv2): GCNConv(16, 7)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3TAi69zI1bO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dcfafa86-519b-450f-bd40-6cd8a0b1f0ce"
      },
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, optimizer, x_type='x', edge_type='edge_index'):\n",
        "\n",
        "      model.train()\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      out = model(data[x_type], data[edge_type])  # Perform a single forward pass.\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      return loss\n",
        "\n",
        "def test(model, x_type='x', edge_type='edge_index'):\n",
        "      model.eval()\n",
        "      out = model(data[x_type], data[edge_type])\n",
        "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
        "      return test_acc\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN different X features noise levels"
      ],
      "metadata": {
        "id": "16hN7hJ780t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_levels = [0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99]\n",
        "x_noises =[f'x_noisy_n_{x}' for x in noise_levels ]\n",
        "\n",
        "x_types=['x', 'x_noisy', 'x_ones'] +x_noises\n",
        "for x_type in x_types:\n",
        "  model = GCN(hidden_channels=16)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "  for epoch in range(1, 101):\n",
        "      loss = train(model, optimizer, x_type=x_type)\n",
        "      #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "  test_acc = test(model, x_type=x_type)\n",
        "  print(f'{x_type} Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrXnf8OtwSX7",
        "outputId": "3349cc00-35ac-4588-fce0-c68f83e2f04b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x Test Accuracy: 0.8150\n",
            "x_noisy Test Accuracy: 0.5680\n",
            "x_ones Test Accuracy: 0.3190\n",
            "x_noisy_n_0.15 Test Accuracy: 0.5790\n",
            "x_noisy_n_0.3 Test Accuracy: 0.5900\n",
            "x_noisy_n_0.45 Test Accuracy: 0.5340\n",
            "x_noisy_n_0.6 Test Accuracy: 0.5360\n",
            "x_noisy_n_0.9 Test Accuracy: 0.5470\n",
            "x_noisy_n_0.95 Test Accuracy: 0.5420\n",
            "x_noisy_n_0.99 Test Accuracy: 0.5130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove x% edges\n",
        "def remove_from_all_edges(edge_index, edges_to_remove_ratio = 0.15):\n",
        "  edges_to_remove_ratio = 0.15\n",
        "  edge_ratio_to_keep = 1 - edges_to_remove_ratio\n",
        "  num_edges_keep= int(edge_ratio_to_keep * edge_index.shape[1])\n",
        "  chose_random_edge_indices = np.random.choice(edge_index.shape[1], num_edges_keep, replace=False)\n",
        "\n",
        "  print(edge_index[0][chose_random_edge_indices].shape)\n",
        "  print(num_edges_keep)\n",
        "  print(edge_index.shape[1])\n",
        "\n",
        "  edge_index_removed = torch.zeros((2,num_edges_keep), dtype=torch.int64)\n",
        "  edge_index_removed[0] = edge_index[0][chose_random_edge_indices]\n",
        "  edge_index_removed[1] = edge_index[1][chose_random_edge_indices]\n",
        "  return edge_index_removed\n",
        "\n",
        "edge_index_removed = remove_from_all_edges(edge_index=data.edge_index, edges_to_remove_ratio = 0.15)\n",
        "data.edge_index_85 = edge_index_removed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpEb0WU4CDR8",
        "outputId": "c5c96267-5325-4908-c7c3-2c847ddb120c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8972])\n",
            "8972\n",
            "10556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ed_type = 'edge_index_85'\n",
        "noise_levels = [0.15, 0.3, 0.45, 0.6, 0.9, 0.95, 0.99]\n",
        "x_noises =[f'x_noisy_n_{x}' for x in noise_levels ]\n",
        "\n",
        "x_types=['x', 'x_noisy', 'x_ones'] +x_noises\n",
        "for x_type in x_types:\n",
        "  model = GCN(hidden_channels=16)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "  for epoch in range(1, 101):\n",
        "      loss = train(model, optimizer,x_type=x_type, edge_type=ed_type)\n",
        "      #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "  test_acc = test(model, x_type=x_type,edge_type=ed_type)\n",
        "  print(f'{x_type} Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAOqlGSmFZy2",
        "outputId": "c48e66ea-db99-45b5-de81-485727951558"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x Test Accuracy: 0.7980\n",
            "x_noisy Test Accuracy: 0.5300\n",
            "x_ones Test Accuracy: 0.3190\n",
            "x_noisy_n_0.15 Test Accuracy: 0.5710\n",
            "x_noisy_n_0.3 Test Accuracy: 0.5790\n",
            "x_noisy_n_0.45 Test Accuracy: 0.5340\n",
            "x_noisy_n_0.6 Test Accuracy: 0.5140\n",
            "x_noisy_n_0.9 Test Accuracy: 0.5030\n",
            "x_noisy_n_0.95 Test Accuracy: 0.5290\n",
            "x_noisy_n_0.99 Test Accuracy: 0.4790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove x% edges from random k, top_k, bottom_k nodes\n",
        "\n",
        "def choose_nodes_to_remove_from(data, num_nodes, k_nodes, remove_type):\n",
        "  if remove_type=='random':\n",
        "    nodes_chosen = torch.tensor([np.random.choice(num_nodes, k_nodes, replace=False)])\n",
        "  elif remove_type=='top_k':\n",
        "    # find indegree edges\n",
        "    dg = torch_geometric.utils.degree(data.edge_index[0])\n",
        "    top_k_nodes_degrees, top_k_nodes_indices = torch.topk(dg, k_nodes)\n",
        "    #print(top_k_nodes_degrees, top_k_nodes_indices)\n",
        "    nodes_chosen = top_k_nodes_indices\n",
        "  elif remove_type=='bottom_k':\n",
        "    # find indegree edges\n",
        "    dg = torch_geometric.utils.degree(data.edge_index[0])\n",
        "    bottom_k_nodes_degrees, bottom_k_nodes_indices = torch.topk(dg, k_nodes, largest=False)\n",
        "    #print(bottom_k_nodes_degrees, bottom_k_nodes_indices)\n",
        "    nodes_chosen = bottom_k_nodes_indices\n",
        "  else:\n",
        "    raise 'remove_type should be from random, top_k, bottom_k'\n",
        "  return nodes_chosen\n",
        "\n",
        "# to do loop for each node separately\n",
        "def remove_edges_from_chosen_nodes(data, nodes_chosen, edges_to_remove_per_node_ratio):\n",
        "  edges_0_list, edges_1_list = [],[]\n",
        "  for nc in nodes_chosen:\n",
        "    edge_0, edge_1 = remove_edge_per_node(data=data, node=nc, \n",
        "                                          edges_to_remove_per_node_ratio=edges_to_remove_per_node_ratio)\n",
        "    edges_0_list.append(edge_0)\n",
        "    edges_1_list.append(edge_1)\n",
        "\n",
        "  edges_0 = torch.cat(edges_0_list, 0)\n",
        "  edges_1 = torch.cat(edges_1_list, 0)\n",
        "\n",
        "  return edges_0, edges_1\n",
        "\n",
        "def remove_edge_per_node(data, node, edges_to_remove_per_node_ratio=0.1):\n",
        "  mask_node_indices = torch.isin(data.edge_index[0], node)\n",
        "\n",
        "  select_node_edges_0 = data.edge_index[0][mask_node_indices]\n",
        "  select_node_edges_1 = data.edge_index[1][mask_node_indices]\n",
        "  #print(select_node_edges_0)\n",
        "  #print(select_node_edges_1)\n",
        "\n",
        "  # choose how much of the edges we will remove for this node\n",
        "  # we decide on number of edges to remove for each node based on the number of edges each node has\n",
        "  # and by taking the ratio given by edges_to_remove_per_node_ratio\n",
        "  # note: we use ceil to remove at least one node (unless ratio is 0)\n",
        "  num_edges_remove = int(math.ceil(edges_to_remove_per_node_ratio* select_node_edges_0.shape[0]))\n",
        "  # print(num_edges_remove)\n",
        "  num_edges_keep = select_node_edges_0.shape[0] - num_edges_remove\n",
        "\n",
        "  # choose random edges to keep, the rest is removed\n",
        "  chose_random_edge_indices = np.random.choice(select_node_edges_0.shape[0], num_edges_keep, replace=False)\n",
        "  # print(num_edges_keep)\n",
        "  \n",
        "  edge_index_removed = torch.zeros((2,num_edges_keep), dtype=torch.int64)\n",
        "  edge_node_index_removed_0 = select_node_edges_0[chose_random_edge_indices]\n",
        "  edge_node_index_removed_1 = select_node_edges_1[chose_random_edge_indices]\n",
        "\n",
        "  return edge_node_index_removed_0, edge_node_index_removed_1\n",
        "\n",
        "def remove_edges_from_nodes(data, edges_to_remove_per_node_ratio = 0.15, k_nodes=10,\n",
        "                            remove_type='random', remove_bidirectional=False):\n",
        "  edge_p_node_ratio_to_keep = 1 - edges_to_remove_per_node_ratio\n",
        "\n",
        "  # choose topk, bottomk, or random\n",
        "  nodes_chosen = choose_nodes_to_remove_from(data=data, num_nodes=data.num_nodes, k_nodes=k_nodes, remove_type=remove_type)\n",
        "\n",
        "  # keep edges from remaining nodes\n",
        "  mask_node_indices = torch.isin(data.edge_index[0],nodes_chosen)\n",
        "  index_keep = torch.ones(data.edge_index[0].shape[0], dtype=bool)\n",
        "  index_keep[mask_node_indices] = False\n",
        "  edges_to_keep_0 = data.edge_index[0][index_keep]\n",
        "  edges_to_keep_1 = data.edge_index[1][index_keep]\n",
        "  #print(edges_to_keep_0) \n",
        "  #print(edges_to_keep_1)\n",
        "\n",
        "  # remove one-directional or bi-directional\n",
        "  edges_0_kept_chosen_nodes, edges_1_kept_chosen_nodes = remove_edges_from_chosen_nodes(data=data, \n",
        "                                                                                        nodes_chosen=nodes_chosen,\n",
        "                                                                                        edges_to_remove_per_node_ratio=edges_to_remove_per_node_ratio)\n",
        "  # concat edges to keep and edges_kept_chosen_nodes\n",
        "  final_edges_0 = torch.cat([edges_to_keep_0, edges_0_kept_chosen_nodes], 0)\n",
        "  final_edges_1 = torch.cat([edges_to_keep_1, edges_1_kept_chosen_nodes], 0)\n",
        "\n",
        "  # do bidirectional here! IF bidirectional set to true remove both directions of the edges.\n",
        "  if remove_bidirectional:\n",
        "    # find the node names deleted in below indices and delete also for the opposite side.\n",
        "    final_edges_bidirec_0 = []\n",
        "    final_edges_bidirec_1 = []\n",
        "\n",
        "    # create a set with all edges\n",
        "    edge_maps = set()\n",
        "    for e_0, e_1 in zip(final_edges_0, final_edges_1):\n",
        "      edge_maps.add((e_0.item(),e_1.item()))\n",
        "\n",
        "    for e_0, e_1 in zip(final_edges_0, final_edges_1):\n",
        "      e_0_val = e_0.item()\n",
        "      e_1_val = e_1.item()\n",
        "      # check an edge has its other direction, if yes add to the final list, if not skip\n",
        "      if (e_0_val, e_1_val) in edge_maps and (e_1_val, e_0_val) in edge_maps:\n",
        "        final_edges_bidirec_0.append(e_0_val) \n",
        "        final_edges_bidirec_1.append(e_1_val)\n",
        "\n",
        "    final_edges_bidirec_0 = torch.tensor(final_edges_bidirec_0)\n",
        "    final_edges_bidirec_1 = torch.tensor(final_edges_bidirec_1)\n",
        "    final_edges_0 = final_edges_bidirec_0\n",
        "    final_edges_1 = final_edges_bidirec_1\n",
        "  edge_index_removed = torch.zeros((2, final_edges_0.shape[0]), dtype=torch.int64)\n",
        "  edge_index_removed[0] = final_edges_0\n",
        "  edge_index_removed[1] = final_edges_1\n",
        "\n",
        "    \n",
        "  # use TORCH_GEOMETRIC.UTILS.SORT_EDGE_INDEX\n",
        "  edge_index_removed_sorted = tg_utils.sort_edge_index(edge_index_removed)\n",
        "  return edge_index_removed_sorted\n"
      ],
      "metadata": {
        "id": "0WSp747oA8MS"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = remove_edges_from_nodes(data=data, edges_to_remove_per_node_ratio = 0.5, k_nodes=1000,\n",
        "                            remove_type='random', remove_bidirectional=False)\n",
        "\n",
        "edges.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja4XxaDHA2db",
        "outputId": "90d8cc7e-07fd-44d9-a743-43bbdf49d9fb"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   2,    2,    2,  ..., 2707, 2707, 2707])\n",
            "tensor([   1,  332, 1454,  ...,  598, 1473, 2706])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10002])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges = remove_edges_from_nodes(data=data, edges_to_remove_per_node_ratio = 0.5, k_nodes=1000,\n",
        "                            remove_type='random', remove_bidirectional=True)\n",
        "\n",
        "edges.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU4znhKOEIOw",
        "outputId": "90ae7e8f-3313-42b2-f544-fb5f81efbb6b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   1,    1,    1,  ..., 2707, 2707, 2707])\n",
            "tensor([   2,  652,  654,  ...,  598, 1473, 2706])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9442])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges = remove_edges_from_nodes(data=data, edges_to_remove_per_node_ratio = 0.5, k_nodes=1000,\n",
        "                            remove_type='top_k', remove_bidirectional=False)\n",
        "edges.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa31gFOl4w9v",
        "outputId": "ac30d5d5-2208-406c-9bb5-719fdffdba47"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   0,    0,    0,  ..., 2703, 2704, 2705])\n",
            "tensor([ 633, 1862, 2582,  ..., 1298,  641,  287])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9124])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add different types of edge removals in the data\n",
        "\n",
        "remove_type = 'bottom_k' #'top_k', 'bottom_k', 'random'\n",
        "remove_bidirectional = True #False, True\n",
        "k_nodes = 1000\n",
        "edges_to_remove_ratios =  [0, 0.1, 0.15, 0.3, 0.45, 0.6, 0.9, 0.95]\n",
        "\n",
        "for remove_ratio in edges_to_remove_ratios:\n",
        "  edges = remove_edges_from_nodes(data=data, edges_to_remove_per_node_ratio = remove_ratio, k_nodes=k_nodes,\n",
        "                              remove_type=remove_type, remove_bidirectional=remove_bidirectional)\n",
        "  print(edges.shape)\n",
        "  data[f'edge_removed_{remove_type}_bidirec_{remove_bidirectional}_nodes_{k_nodes}_ratio_{remove_ratio}'] = edges\n",
        "\n",
        "\n",
        "edge_noises = [f'edge_removed_{remove_type}_bidirec_{remove_bidirectional}_nodes_{k_nodes}_ratio_{x}' for x in edges_to_remove_ratios ]\n",
        "edge_types = ['edge_index'] + edge_noises\n",
        "\n",
        "for ed_type in edge_types:\n",
        "  model = GCN(hidden_channels=16)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "  for epoch in range(1, 101):\n",
        "      loss = train(model, optimizer, x_type='x', edge_type=ed_type)\n",
        "      #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "  test_acc = test(model, x_type='x',edge_type=ed_type)\n",
        "  print(f'{ed_type} Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfXKKchRKsgt",
        "outputId": "d10cb3e0-9cbf-4edf-bd8e-0e6d23f63092"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 10556])\n",
            "torch.Size([2, 8782])\n",
            "torch.Size([2, 8758])\n",
            "torch.Size([2, 8766])\n",
            "torch.Size([2, 8768])\n",
            "torch.Size([2, 7922])\n",
            "torch.Size([2, 7922])\n",
            "torch.Size([2, 7922])\n",
            "edge_index Test Accuracy: 0.8150\n",
            "edge_removed_bottom_k_bidirec_True_nodes_1000_ratio_0 Test Accuracy: 0.8150\n",
            "edge_removed_bottom_k_bidirec_True_nodes_1000_ratio_0.1 Test Accuracy: 0.7850\n",
            "edge_removed_bottom_k_bidirec_True_nodes_1000_ratio_0.15 Test Accuracy: 0.7770\n",
            "edge_removed_bottom_k_bidirec_True_nodes_1000_ratio_0.3 Test Accuracy: 0.7890\n",
            "edge_removed_bottom_k_bidirec_True_nodes_1000_ratio_0.45 Test Accuracy: 0.7760\n",
            "edge_removed_bottom_k_bidirec_True_nodes_1000_ratio_0.6 Test Accuracy: 0.7660\n",
            "edge_removed_bottom_k_bidirec_True_nodes_1000_ratio_0.9 Test Accuracy: 0.7660\n",
            "edge_removed_bottom_k_bidirec_True_nodes_1000_ratio_0.95 Test Accuracy: 0.7660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODOs:\n",
        "# TODO remove bidirectional - DONE\n",
        "\n",
        "# TODO add edges:\n",
        "  # TODO add random edges\n",
        "  # TODO add edges to top k node \n",
        "  # TODO add edges to bottom k node \n",
        "  # TODO add edges to random k node \n",
        "\n",
        "# decide on experiments\n",
        "# experiments/research questions\n",
        "# decide on datasets\n",
        "# decide models to use (mlp, gnn, graphsage, ??)\n",
        "# decide on what to log, save, how to design experiments \n",
        "# reliability of experiments: 10 experiments and avg results (log each experiment)\n",
        "# Run each experiment\n",
        "# plots for experiments"
      ],
      "metadata": {
        "id": "841jfXxUTrMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_edges(edge_index, node_num, added_level = 0.15):\n",
        "  new_edges = edge_index.T\n",
        "  edge_num = new_edges.shape[0]\n",
        "  num_of_new_edges = int(edge_num * added_level)\n",
        "\n",
        "  for i in range(num_of_new_edges):\n",
        "    while True:\n",
        "      new_edge = ((torch.rand(1,2) * 100000).to(int) % node_num)\n",
        "      new_edge_flip = torch.flip(new_edge, [1])\n",
        "      if not torch.any(torch.all(torch.eq(new_edges,new_edge),1)):\n",
        "        new_edges = torch.cat((new_edges,new_edge), 0)\n",
        "        break\n",
        "      elif not torch.any(torch.all(torch.eq(new_edges,new_edge_flip),1)):\n",
        "        new_edges = torch.cat((new_edges,new_edge_flip), 0)\n",
        "        break\n",
        "      \n",
        "  return new_edges.T"
      ],
      "metadata": {
        "id": "Ng5JaRtrBctF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for added_level in [0.15, 0.3, 0.45, 0.6, 0.9, 1.2]:\n",
        "  added_edge_index = add_edges(data.edge_index, data.x.shape[0],  added_level=added_level)\n",
        "  data[f'edge_index_added_n_{added_level}'] = added_edge_index"
      ],
      "metadata": {
        "id": "xbJwlz_CRnm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "added_levels = [0.15, 0.3, 0.45, 0.6, 0.9, 1.2]\n",
        "edge_noises = [f'edge_index_added_n_{x}' for x in added_levels ]\n",
        "edge_types = ['edge_index'] + edge_noises\n",
        "\n",
        "for ed_type in edge_types:\n",
        "  model = GCN(hidden_channels=16)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "  for epoch in range(1, 101):\n",
        "      loss = train(model, optimizer, x_type='x', edge_type=ed_type)\n",
        "      #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "  test_acc = test(model, x_type='x',edge_type=ed_type)\n",
        "  print(f'{ed_type} Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXWHVZPlE_I1",
        "outputId": "909d78e5-359e-49cd-848b-2cf1eecd3d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "edge_index Test Accuracy: 0.8150\n",
            "edge_index_added_n_0.15 Test Accuracy: 0.7440\n",
            "edge_index_added_n_0.3 Test Accuracy: 0.7070\n",
            "edge_index_added_n_0.45 Test Accuracy: 0.6490\n",
            "edge_index_added_n_0.6 Test Accuracy: 0.6210\n",
            "edge_index_added_n_0.9 Test Accuracy: 0.5520\n",
            "edge_index_added_n_1.2 Test Accuracy: 0.5310\n"
          ]
        }
      ]
    }
  ]
}